{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72dc8e59",
   "metadata": {},
   "source": [
    "# steps to counting over all of MAG as represented here...\n",
    "\n",
    "+ identify subset to handle\n",
    "+ gather publication years of papers\n",
    "+ gather paper -> author dictionary\n",
    "+ loop over citations, and do some counting! // just use paper IDs for everything\n",
    "+ save a dictionary which maps from the IDs to something meaningful, for later lookup (Title, Year, Authors) {how big is this dictionary?}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2f5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e696ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class counter:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            output_database, name_blacklist=[],\n",
    "            RUN_EVERYTHING=True,\n",
    "            groups=None, group_reps=None,\n",
    "            citations_filter=None, journals_filter=None, debug=False,\n",
    "            trimCounters=False, wos_type='csv'\n",
    "    ):\n",
    "\n",
    "        self.name_blacklist = name_blacklist\n",
    "        self.debug = debug\n",
    "        self.output_database = output_database\n",
    "        self.groups = groups\n",
    "        self.group_reps = group_reps\n",
    "\n",
    "        self.wos_type = wos_type\n",
    "\n",
    "        self.RUN_EVERYTHING = RUN_EVERYTHING\n",
    "        self.citations_filter = citations_filter\n",
    "        self.journals_filter = journals_filter\n",
    "        self.trimCounters = trimCounters\n",
    "\n",
    "        # Instantiating counters\n",
    "        self.ind = defaultdict(lambda: defaultdict(int))\n",
    "        self.track_doc = defaultdict(lambda: defaultdict(set))\n",
    "        self.doc = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    def cnt(self, term, space, doc):\n",
    "        if \".\".join(sorted(space.split(\".\"))) != space:\n",
    "            raise Exception(space, \"should be sorted...\")\n",
    "\n",
    "        if type(term) != tuple:\n",
    "            term = tuple([term])\n",
    "\n",
    "        # it's a set, yo\n",
    "        self.track_doc[space][term].add(doc)\n",
    "        # update cnt_doc\n",
    "        self.doc[space][term] = len(self.track_doc[space][term])\n",
    "        # update ind count\n",
    "        self.ind[space][term] += 1\n",
    "\n",
    "    def save_counters(self):\n",
    "        db = Dataset(self.output_database)\n",
    "        db.clear_all()\n",
    "\n",
    "        db.save_variable('_attributes', {})\n",
    "\n",
    "        for k, count in self.doc.items():\n",
    "            varname = \"doc ___ %s\" % k\n",
    "            db.save_variable(varname, dict(count))\n",
    "\n",
    "        for k, count in self.ind.items():\n",
    "            varname = \"ind ___ %s\" % k\n",
    "            db.save_variable(varname, dict(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3571e0f",
   "metadata": {},
   "source": [
    "# step 0... reload the sociology papers identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb02449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('soc_papers.pickle', 'rb') as inf:\n",
    "    socpapers = pickle.load(inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb41c2",
   "metadata": {},
   "source": [
    "# step 1... go get pub years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7fd5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genlim(limit):\n",
    "    def limiter(gen):\n",
    "        for i,item in enumerate(gen):\n",
    "            if i > limit:\n",
    "                break\n",
    "            yield item\n",
    "    return limiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fabe3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizing I need info for EVERYTHING\n",
    "# or, at least what was citing, + cited, at least 5 times...\n",
    "# because I was considering all the cited, of sociologists.\n",
    "# thinking of sociologists as the actors...\n",
    "# my current dataset isn't going to be comparable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d449e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10.0M docs. Got 88,062 papers' info\n",
      "Processed 20.0M docs. Got 176,051 papers' info\n",
      "Processed 30.0M docs. Got 264,550 papers' info\n",
      "Processed 40.0M docs. Got 352,464 papers' info\n",
      "Processed 50.0M docs. Got 440,556 papers' info\n",
      "Processed 60.0M docs. Got 528,856 papers' info\n",
      "Processed 70.0M docs. Got 616,949 papers' info\n",
      "Processed 80.0M docs. Got 705,498 papers' info\n",
      "Processed 90.0M docs. Got 793,453 papers' info\n",
      "Processed 100.0M docs. Got 881,421 papers' info\n",
      "Processed 110.0M docs. Got 969,083 papers' info\n",
      "Processed 120.0M docs. Got 1,058,295 papers' info\n",
      "Processed 130.0M docs. Got 1,146,779 papers' info\n",
      "Processed 140.0M docs. Got 1,234,605 papers' info\n",
      "Processed 150.0M docs. Got 1,322,931 papers' info\n",
      "Processed 160.0M docs. Got 1,411,341 papers' info\n",
      "Processed 170.0M docs. Got 1,499,565 papers' info\n",
      "Processed 180.0M docs. Got 1,587,481 papers' info\n",
      "Processed 190.0M docs. Got 1,674,865 papers' info\n",
      "Processed 200.0M docs. Got 1,762,886 papers' info\n",
      "Processed 210.0M docs. Got 1,851,131 papers' info\n",
      "Processed 220.0M docs. Got 1,939,271 papers' info\n",
      "Processed 230.0M docs. Got 2,027,093 papers' info\n",
      "Processed 240.0M docs. Got 2,115,732 papers' info\n",
      "Processed 250.0M docs. Got 2,204,053 papers' info\n"
     ]
    }
   ],
   "source": [
    "infos = {}\n",
    "#typs = categorical()\n",
    "journals = categorical()\n",
    "\n",
    "with Path(home,'datasets/s4/MAG/Papers.txt').open() as inf:\n",
    "    for i,l in enumerate(inf):\n",
    "        l = l.split('\\t')\n",
    "        if (i+1) % 1e7 == 0: # there are something like 100M papers!, i.e. 1e8\n",
    "            print('Processed', f\"{(i+1)//1e6:,}M\", 'docs. Got', f\"{len(infos):,}\", 'papers\\' info')\n",
    "            \n",
    "        my_id = int(l[0])\n",
    "        \n",
    "        if my_id not in socpapers:\n",
    "            continue\n",
    "        \n",
    "        if l[7] == '': # saw this for some dataset... idk why. very rare\n",
    "            continue\n",
    "        \n",
    "        if l[3] != 'Journal':\n",
    "            continue\n",
    "        \n",
    "        year = int(l[7])\n",
    "        #typ = typs[ l[3] ]\n",
    "        journal = journals[ l[11] ]\n",
    "        \n",
    "        infos[my_id] = [year, journal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70381216",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('infos_citing.pickle', 'wb') as outf:\n",
    "    pickle.dump( (infos, journals), outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f25a5d",
   "metadata": {},
   "source": [
    "# gather citations from these docs, to judge what extra info I need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74e96c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation link 10,000,000. Collected 43,489 citations.\n",
      "Citation link 20,000,000. Collected 86,145 citations.\n",
      "Citation link 30,000,000. Collected 130,648 citations.\n",
      "Citation link 40,000,000. Collected 172,844 citations.\n",
      "Citation link 50,000,000. Collected 216,538 citations.\n",
      "Citation link 60,000,000. Collected 298,175 citations.\n",
      "Citation link 70,000,000. Collected 393,697 citations.\n",
      "Citation link 80,000,000. Collected 458,035 citations.\n",
      "Citation link 90,000,000. Collected 479,047 citations.\n",
      "Citation link 100,000,000. Collected 549,275 citations.\n",
      "Citation link 110,000,000. Collected 643,777 citations.\n",
      "Citation link 120,000,000. Collected 738,918 citations.\n",
      "Citation link 130,000,000. Collected 836,498 citations.\n",
      "Citation link 140,000,000. Collected 927,998 citations.\n",
      "Citation link 150,000,000. Collected 1,019,950 citations.\n",
      "Citation link 160,000,000. Collected 1,112,978 citations.\n",
      "Citation link 170,000,000. Collected 1,208,542 citations.\n",
      "Citation link 180,000,000. Collected 1,300,100 citations.\n",
      "Citation link 190,000,000. Collected 1,388,973 citations.\n",
      "Citation link 200,000,000. Collected 1,490,812 citations.\n",
      "Citation link 210,000,000. Collected 1,594,464 citations.\n",
      "Citation link 220,000,000. Collected 1,695,459 citations.\n",
      "Citation link 230,000,000. Collected 1,801,532 citations.\n",
      "Citation link 240,000,000. Collected 1,909,368 citations.\n",
      "Citation link 250,000,000. Collected 2,061,778 citations.\n",
      "Citation link 260,000,000. Collected 2,218,483 citations.\n",
      "Citation link 270,000,000. Collected 2,376,793 citations.\n",
      "Citation link 280,000,000. Collected 2,529,942 citations.\n",
      "Citation link 290,000,000. Collected 2,681,025 citations.\n",
      "Citation link 300,000,000. Collected 2,833,661 citations.\n",
      "Citation link 310,000,000. Collected 2,985,776 citations.\n",
      "Citation link 320,000,000. Collected 3,137,771 citations.\n",
      "Citation link 330,000,000. Collected 3,295,801 citations.\n",
      "Citation link 340,000,000. Collected 3,446,703 citations.\n",
      "Citation link 350,000,000. Collected 3,600,623 citations.\n",
      "Citation link 360,000,000. Collected 3,751,972 citations.\n",
      "Citation link 370,000,000. Collected 3,908,127 citations.\n",
      "Citation link 380,000,000. Collected 4,064,345 citations.\n",
      "Citation link 390,000,000. Collected 4,219,529 citations.\n",
      "Citation link 400,000,000. Collected 4,375,465 citations.\n",
      "Citation link 410,000,000. Collected 4,532,587 citations.\n",
      "Citation link 420,000,000. Collected 4,691,816 citations.\n",
      "Citation link 430,000,000. Collected 4,848,252 citations.\n",
      "Citation link 440,000,000. Collected 5,001,639 citations.\n",
      "Citation link 450,000,000. Collected 5,157,156 citations.\n",
      "Citation link 460,000,000. Collected 5,311,297 citations.\n",
      "Citation link 470,000,000. Collected 5,466,255 citations.\n",
      "Citation link 480,000,000. Collected 5,622,321 citations.\n",
      "Citation link 490,000,000. Collected 5,778,265 citations.\n",
      "Citation link 500,000,000. Collected 5,935,009 citations.\n",
      "Citation link 510,000,000. Collected 6,093,368 citations.\n",
      "Citation link 520,000,000. Collected 6,244,397 citations.\n",
      "Citation link 530,000,000. Collected 6,400,179 citations.\n",
      "Citation link 540,000,000. Collected 6,554,912 citations.\n",
      "Citation link 550,000,000. Collected 6,713,205 citations.\n",
      "Citation link 560,000,000. Collected 6,867,759 citations.\n",
      "Citation link 570,000,000. Collected 7,023,090 citations.\n",
      "Citation link 580,000,000. Collected 7,176,269 citations.\n",
      "Citation link 590,000,000. Collected 7,333,284 citations.\n",
      "Citation link 600,000,000. Collected 7,484,899 citations.\n",
      "Citation link 610,000,000. Collected 7,638,776 citations.\n",
      "Citation link 620,000,000. Collected 7,792,097 citations.\n",
      "Citation link 630,000,000. Collected 7,949,709 citations.\n",
      "Citation link 640,000,000. Collected 8,106,677 citations.\n",
      "Citation link 650,000,000. Collected 8,261,811 citations.\n",
      "Citation link 660,000,000. Collected 8,419,190 citations.\n",
      "Citation link 670,000,000. Collected 8,575,013 citations.\n",
      "Citation link 680,000,000. Collected 8,729,802 citations.\n",
      "Citation link 690,000,000. Collected 8,887,794 citations.\n",
      "Citation link 700,000,000. Collected 9,044,751 citations.\n",
      "Citation link 710,000,000. Collected 9,203,353 citations.\n",
      "Citation link 720,000,000. Collected 9,365,574 citations.\n",
      "Citation link 730,000,000. Collected 9,517,854 citations.\n",
      "Citation link 740,000,000. Collected 9,672,880 citations.\n",
      "Citation link 750,000,000. Collected 9,828,369 citations.\n",
      "Citation link 760,000,000. Collected 9,978,637 citations.\n",
      "Citation link 770,000,000. Collected 10,130,618 citations.\n",
      "Citation link 780,000,000. Collected 10,279,573 citations.\n",
      "Citation link 790,000,000. Collected 10,427,142 citations.\n",
      "Citation link 800,000,000. Collected 10,577,615 citations.\n",
      "Citation link 810,000,000. Collected 10,727,781 citations.\n",
      "Citation link 820,000,000. Collected 10,876,212 citations.\n",
      "Citation link 830,000,000. Collected 11,026,516 citations.\n",
      "Citation link 840,000,000. Collected 11,183,493 citations.\n",
      "Citation link 850,000,000. Collected 11,337,562 citations.\n",
      "Citation link 860,000,000. Collected 11,493,188 citations.\n",
      "Citation link 870,000,000. Collected 11,646,320 citations.\n",
      "Citation link 880,000,000. Collected 11,801,645 citations.\n",
      "Citation link 890,000,000. Collected 11,954,651 citations.\n",
      "Citation link 900,000,000. Collected 12,106,665 citations.\n",
      "Citation link 910,000,000. Collected 12,263,768 citations.\n",
      "Citation link 920,000,000. Collected 12,418,059 citations.\n",
      "Citation link 930,000,000. Collected 12,574,578 citations.\n",
      "Citation link 940,000,000. Collected 12,725,970 citations.\n",
      "Citation link 950,000,000. Collected 12,877,700 citations.\n",
      "Citation link 960,000,000. Collected 13,030,824 citations.\n",
      "Citation link 970,000,000. Collected 13,185,296 citations.\n",
      "Citation link 980,000,000. Collected 13,330,198 citations.\n",
      "Citation link 990,000,000. Collected 13,382,685 citations.\n",
      "Citation link 1,000,000,000. Collected 13,409,824 citations.\n",
      "Citation link 1,010,000,000. Collected 13,473,647 citations.\n",
      "Citation link 1,020,000,000. Collected 13,548,966 citations.\n",
      "Citation link 1,030,000,000. Collected 13,620,291 citations.\n",
      "Citation link 1,040,000,000. Collected 13,662,905 citations.\n",
      "Citation link 1,050,000,000. Collected 13,735,635 citations.\n",
      "Citation link 1,060,000,000. Collected 13,808,444 citations.\n",
      "Citation link 1,070,000,000. Collected 13,875,258 citations.\n",
      "Citation link 1,080,000,000. Collected 13,957,239 citations.\n",
      "Citation link 1,090,000,000. Collected 14,041,655 citations.\n",
      "Citation link 1,100,000,000. Collected 14,179,990 citations.\n",
      "Citation link 1,110,000,000. Collected 14,337,345 citations.\n",
      "Citation link 1,120,000,000. Collected 14,489,872 citations.\n",
      "Citation link 1,130,000,000. Collected 14,615,502 citations.\n",
      "Citation link 1,140,000,000. Collected 14,703,525 citations.\n",
      "Citation link 1,150,000,000. Collected 14,751,191 citations.\n",
      "Citation link 1,160,000,000. Collected 14,807,942 citations.\n",
      "Citation link 1,170,000,000. Collected 14,911,510 citations.\n",
      "Citation link 1,180,000,000. Collected 14,995,932 citations.\n",
      "Citation link 1,190,000,000. Collected 15,045,799 citations.\n",
      "Citation link 1,200,000,000. Collected 15,095,759 citations.\n",
      "Citation link 1,210,000,000. Collected 15,209,942 citations.\n",
      "Citation link 1,220,000,000. Collected 15,321,707 citations.\n",
      "Citation link 1,230,000,000. Collected 15,427,531 citations.\n",
      "Citation link 1,240,000,000. Collected 15,529,048 citations.\n",
      "Citation link 1,250,000,000. Collected 15,642,725 citations.\n",
      "Citation link 1,260,000,000. Collected 15,768,717 citations.\n",
      "Citation link 1,270,000,000. Collected 15,880,456 citations.\n",
      "Citation link 1,280,000,000. Collected 16,013,135 citations.\n",
      "Citation link 1,290,000,000. Collected 16,127,486 citations.\n",
      "Citation link 1,300,000,000. Collected 16,244,715 citations.\n",
      "Citation link 1,310,000,000. Collected 16,359,284 citations.\n",
      "Citation link 1,320,000,000. Collected 16,448,490 citations.\n",
      "Citation link 1,330,000,000. Collected 16,554,357 citations.\n",
      "Citation link 1,340,000,000. Collected 16,668,952 citations.\n",
      "Citation link 1,350,000,000. Collected 16,772,691 citations.\n",
      "Citation link 1,360,000,000. Collected 16,859,487 citations.\n",
      "Citation link 1,370,000,000. Collected 16,957,289 citations.\n",
      "Citation link 1,380,000,000. Collected 17,063,808 citations.\n",
      "Citation link 1,390,000,000. Collected 17,168,198 citations.\n",
      "Citation link 1,400,000,000. Collected 17,268,425 citations.\n",
      "Citation link 1,410,000,000. Collected 17,286,111 citations.\n",
      "Citation link 1,420,000,000. Collected 17,292,694 citations.\n",
      "Citation link 1,430,000,000. Collected 17,298,095 citations.\n",
      "Citation link 1,440,000,000. Collected 17,367,847 citations.\n",
      "Citation link 1,450,000,000. Collected 17,465,946 citations.\n",
      "Citation link 1,460,000,000. Collected 17,563,163 citations.\n",
      "Citation link 1,470,000,000. Collected 17,660,019 citations.\n",
      "Citation link 1,480,000,000. Collected 17,755,461 citations.\n",
      "Citation link 1,490,000,000. Collected 17,856,198 citations.\n",
      "Citation link 1,500,000,000. Collected 17,929,851 citations.\n",
      "Citation link 1,510,000,000. Collected 17,980,323 citations.\n",
      "Citation link 1,520,000,000. Collected 18,078,936 citations.\n",
      "Citation link 1,530,000,000. Collected 18,138,808 citations.\n",
      "Citation link 1,540,000,000. Collected 18,205,752 citations.\n",
      "Citation link 1,550,000,000. Collected 18,256,384 citations.\n",
      "Citation link 1,560,000,000. Collected 18,338,224 citations.\n",
      "Citation link 1,570,000,000. Collected 18,421,104 citations.\n",
      "Citation link 1,580,000,000. Collected 18,508,501 citations.\n",
      "Citation link 1,590,000,000. Collected 18,603,629 citations.\n",
      "Citation link 1,600,000,000. Collected 18,697,518 citations.\n",
      "Citation link 1,610,000,000. Collected 18,784,274 citations.\n",
      "Citation link 1,620,000,000. Collected 18,873,352 citations.\n",
      "Citation link 1,630,000,000. Collected 18,948,701 citations.\n",
      "Citation link 1,640,000,000. Collected 19,016,814 citations.\n",
      "Citation link 1,650,000,000. Collected 19,103,208 citations.\n",
      "Citation link 1,660,000,000. Collected 19,189,669 citations.\n",
      "Citation link 1,670,000,000. Collected 19,273,383 citations.\n",
      "Citation link 1,680,000,000. Collected 19,347,830 citations.\n",
      "Citation link 1,690,000,000. Collected 19,418,774 citations.\n",
      "Citation link 1,700,000,000. Collected 19,483,803 citations.\n",
      "Citation link 1,710,000,000. Collected 19,506,620 citations.\n",
      "Citation link 1,720,000,000. Collected 19,566,562 citations.\n",
      "Citation link 1,730,000,000. Collected 19,650,533 citations.\n",
      "Citation link 1,740,000,000. Collected 19,763,874 citations.\n"
     ]
    }
   ],
   "source": [
    "cits = []\n",
    "with Path(home, 'datasets/s4/MAG/PaperReferences.txt').open() as inf:\n",
    "    for i,l in enumerate(inf):\n",
    "        if (i+1)%1e7 == 0:\n",
    "            print(f\"Citation link {i+1:,}. Collected {len(cits):,} citations.\")\n",
    "            \n",
    "        l = l[:-1] # strip the trailing \\n from the line\n",
    "        l = l.split('\\t') # tab delimited\n",
    "        l = list(map(int,l)) # map to integers. saving on memory this way hopefully\n",
    "        \n",
    "        if l[0] in infos:\n",
    "            cits.append([l[0], l[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0b19f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the cited that get at least 5 citations\n",
    "ccits = Counter([x[1] for x in cits])\n",
    "cited_to_keep = set([x for x,v in ccits.items() if v>=5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0256b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cited_to_keep.pickle', 'wb') as outf:\n",
    "    pickle.dump( cited_to_keep, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5debac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cits.pickle', 'wb') as outf:\n",
    "    pickle.dump( cits, outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c55392",
   "metadata": {},
   "source": [
    "# going to have to go back & get info for everyone now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "651145b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10.0M docs. Got 2,222,638 papers' info\n",
      "Processed 20.0M docs. Got 2,222,638 papers' info\n",
      "Processed 30.0M docs. Got 2,222,638 papers' info\n",
      "Processed 40.0M docs. Got 2,222,638 papers' info\n",
      "Processed 50.0M docs. Got 2,222,638 papers' info\n",
      "Processed 60.0M docs. Got 2,222,638 papers' info\n",
      "Processed 70.0M docs. Got 2,222,638 papers' info\n",
      "Processed 80.0M docs. Got 2,222,638 papers' info\n",
      "Processed 90.0M docs. Got 2,222,638 papers' info\n",
      "Processed 100.0M docs. Got 2,222,638 papers' info\n",
      "Processed 110.0M docs. Got 2,222,638 papers' info\n",
      "Processed 120.0M docs. Got 2,222,638 papers' info\n",
      "Processed 130.0M docs. Got 2,222,638 papers' info\n",
      "Processed 140.0M docs. Got 2,222,638 papers' info\n",
      "Processed 150.0M docs. Got 2,222,638 papers' info\n",
      "Processed 160.0M docs. Got 2,222,638 papers' info\n",
      "Processed 170.0M docs. Got 2,222,638 papers' info\n",
      "Processed 180.0M docs. Got 2,222,638 papers' info\n",
      "Processed 190.0M docs. Got 2,222,638 papers' info\n",
      "Processed 200.0M docs. Got 2,222,638 papers' info\n",
      "Processed 210.0M docs. Got 2,222,638 papers' info\n",
      "Processed 220.0M docs. Got 2,222,638 papers' info\n",
      "Processed 230.0M docs. Got 2,222,638 papers' info\n",
      "Processed 240.0M docs. Got 2,222,638 papers' info\n",
      "Processed 250.0M docs. Got 2,222,638 papers' info\n"
     ]
    }
   ],
   "source": [
    "infos_new = {}\n",
    "typs = categorical()\n",
    "journals = categorical()\n",
    "\n",
    "with Path(home,'datasets/s4/MAG/Papers.txt').open() as inf:\n",
    "    for i,l in enumerate(inf):\n",
    "        l = l.split('\\t')\n",
    "        if (i+1) % 1e7 == 0: # there are something like 100M papers!, i.e. 1e8\n",
    "            print('Processed', f\"{(i+1)//1e6:,}M\", 'docs. Got', f\"{len(infos_new):,}\", 'papers\\' info')\n",
    "            \n",
    "        my_id = int(l[0])\n",
    "        \n",
    "        if my_id not in socpapers and my_id not in cited_to_keep:\n",
    "            continue\n",
    "        \n",
    "        if l[7] == '': # very rare. dataset.\n",
    "            continue\n",
    "        \n",
    "        year = int(l[7])\n",
    "        typ = typs[ l[3] ]\n",
    "        journal = journals[ l[11] ]\n",
    "        \n",
    "        infos_new[my_id] = [year, typ, journal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d542bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('infos_all.pickle', 'wb') as outf:\n",
    "    pickle.dump( (infos_new, journals), outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dac7fc",
   "metadata": {},
   "source": [
    "# something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f7a52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the journal names...\n",
    "jnames = {}\n",
    "\n",
    "with Path(home,'datasets/s4/MAG/Journals.txt').open() as inf:\n",
    "    for i,l in enumerate(inf):\n",
    "        l = l.split('\\t')\n",
    "        \n",
    "        ji = int(l[0])\n",
    "        jnames[ji] = l[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cbb4800",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'typs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bd77e85a16ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtyps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'typs' is not defined"
     ]
    }
   ],
   "source": [
    "typs.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f488c23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typs['Journal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2606817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    # get rid of everything except Journal articles...\n",
    "    # hopefully this is effective\n",
    "\n",
    "    socpapers_filt = set()\n",
    "    for ii, (typ, year) in infos.items():\n",
    "        if typ == typs['Journal']:\n",
    "            socpapers_filt.add(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fdb4d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2222638, 4688396)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(socpapers_filt), len(socpapers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8be34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affiliation link 10,000,000. Collected authors for 98,110 out of 5,215,196.\n",
      "Affiliation link 20,000,000. Collected authors for 200,709 out of 5,215,196.\n"
     ]
    }
   ],
   "source": [
    "authors = defaultdict(set)\n",
    "fauthors = {}\n",
    "\n",
    "with Path(home,'datasets/s4/MAG/PaperAuthorAffiliations.txt').open() as inf:\n",
    "    for i,l in enumerate(inf):\n",
    "        if (i+1)%1e7 == 0:\n",
    "            print(f'Affiliation link {i+1:,}. Collected authors for {len(authors):,} out of {len(infos_new):,}.')\n",
    "            \n",
    "        l = l.split('\\t')\n",
    "        \n",
    "        pi = int(l[0])\n",
    "        ai = int(l[1])\n",
    "        \n",
    "        seq = int(l[3])\n",
    "        \n",
    "        if pi not in infos_new:\n",
    "            continue\n",
    "        \n",
    "        authors[pi].add(ai)\n",
    "        if seq == 0:\n",
    "            fauthors[pi] = ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30206fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.688969e+06, 3.309370e+05, 1.179740e+05, 4.515000e+04,\n",
       "        0.000000e+00, 1.841300e+04, 9.294000e+03, 4.410000e+03,\n",
       "        2.613000e+03, 1.434000e+03]),\n",
       " array([1. , 1.8, 2.6, 3.4, 4.2, 5. , 5.8, 6.6, 7.4, 8.2, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEACAYAAACTXJylAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYPUlEQVR4nO3df1AU9+HG8efwJKTCGISAP1BjoikE6ySaZIZgSmpBbcw/NbZQJdqaxGa0jdrSScQf2GAZyIjTmthpSmxMMFOJyFhnkilOZ0xiR/wR0uogZxWtVNEAJ1qCiAbZ7x9+c5ECLsfdcXzi+/UXu59l71lgHpbP7bIOy7IsAQCMERLsAAAA71DcAGAYihsADENxA4BhKG4AMAzFDQCG6bfiPn78uFJTU7V169Zbbnfs2DHNnj1bs2fP1u9///t+SgcA5uiX4m5tbVVubq6SkpJst129erVyc3NVWlqqmpoaXblypR8SAoA5+qW4Q0NDVVRUpJiYGM+6mpoazZ8/XwsWLNDixYvV3Nwst9ut1tZWJSYmKiQkRBs2bNCdd97ZHxEBwBj9UtxOp1NhYWGd1uXm5uqVV17R22+/reTkZL377ruqq6tTVFSUfv3rX2vu3LnasmVLf8QDAKM4g/XCR44c0erVqyVJ165d07e+9S1ZlqXTp0/rd7/7ncLCwpSenq7HHntM999/f7BiAsCAE7TivvPOO/XOO+/I4XB41p05c0YTJkxQZGSkJGnKlCmqqamhuAHgJkG7HDA+Pl4ff/yxJOn9999XRUWFRo8ercuXL+vSpUvq6OiQy+XSvffeG6yIADAgOfrjvwNWVVWpoKBAdXV1cjqdio2N1bJly1RYWKiQkBDdcccdKiws1F133aXDhw9r/fr1unr1qh5//HH9/Oc/D3Q8ADBKvxQ3AMB/uHMSAAxDcQOAYfrlqpLKysr+eBkA+NqZMmVKl3X9djlgdy/eGy6XSwkJCX5O4ztyeYdc3iGXd76uuXo66WWqBAAMQ3EDgGEobgAwDMUNAIahuAHAMBQ3ABiG4gYAw1DcAGCYoP0/7t763tunJJ3q99c9nT+r318TAHqDM24AMAzFDQCGobgBwDAUNwAYhuIGAMNQ3ABgmF4V9/Hjx5WamqqtW7d2GTt//rx+9KMfac6cOVqzZo3fAwIAOrMt7tbWVuXm5iopKanb8fz8fC1cuFClpaUaNGiQzp075/eQAICv2BZ3aGioioqKFBMT02Wso6NDlZWVmjZtmiQpJydHI0eO9H9KAICHbXE7nU6FhYV1O9bU1KTw8HBt3LhRmZmZKiwslGVZfg8JAPiKT7e8W5al+vp6Pf3003rxxRe1aNEiffTRR3riiSe6bOtyuXx5qX5nl7etrW1AHhO5vEMu75DLO4HK5VNxR0ZGasSIERozZowkKSkpSSdOnOi2uPv+wMz+/z8lkn3er+vDSQOFXN4hl3e+rrkC8rBgp9Op0aNH6/Tp05Kko0ePaty4cb7sEgBgw/aMu6qqSgUFBaqrq5PT6VR5ebmmTZumuLg4paWlKTs7Wzk5Obp69aomTJjgeaMSABAYtsU9ceJEFRcX9zg+duxYbdmyxZ+ZAAC3wJ2TAGAYihsADENxA4BhKG4AMAzFDQCGobgBwDAUNwAYhuIGAMNQ3ABgGIobAAxDcQOAYShuADAMxQ0AhqG4AcAwFDcAGIbiBgDD9Kq4jx8/rtTUVG3durXHbQoLC/XMM8/4LRgAoHu2xd3a2qrc3FwlJSX1uE1NTY0OHTrk12AAgO7ZFndoaKiKiooUExPT4zb5+flavny5X4MBALpn+8xJp9Mpp7PnzcrKyvToo49q1KhRfg0GAOiebXHfyqVLl1RWVqa33npL9fX1t9zW5XL58lL9zi5vW1vbgDwmcnmHXN4hl3cClcun4t6/f7+ampo0b948Xbt2Tf/5z3+Ul5en7OzsLtsmJCT08VVO+RKxz+zyulwuH44pcMjlHXJ5h1ze8TVXZWVlt+t9Ku6ZM2dq5syZkqSzZ89qxYoV3ZY2AMB/bIu7qqpKBQUFqqurk9PpVHl5uaZNm6a4uDilpaX1R0YAwE1si3vixIkqLi623VFcXFyvtgMA+IY7JwHAMBQ3ABiG4gYAw1DcAGAYihsADENxA4BhKG4AMAzFDQCGobgBwDAUNwAYhuIGAMNQ3ABgGIobAAxDcQOAYShuADAMxQ0AhulVcR8/flypqanaunVrl7H9+/frhz/8oTIyMrRixQp1dHT4PSQA4Cu2xd3a2qrc3FwlJSV1O75mzRpt3LhR27Zt0+XLl7V3716/hwQAfMW2uENDQ1VUVKSYmJhux8vKyjR8+HBJ0rBhw3Tx4kX/JgQAdGL7zEmn0ymns+fNwsPDJUkNDQ3at2+fli5d2u12LperjxGDwy5vW1vbgDwmcnmHXN4hl3cClcu2uHvjwoULeuGFF7RmzRpFRkZ2u01CQkIf936q78F8YJfX5XL5cEyBQy7vkMs75PKOr7kqKyu7Xe/zVSUtLS16/vnntXTpUk2dOtXX3QEAbPhc3Pn5+VqwYIFSUlL8kQcAYMN2qqSqqkoFBQWqq6uT0+lUeXm5pk2bpri4OE2dOlU7d+5UbW2tSktLJUlPPfWU0tPTAx4cAG5XtsU9ceJEFRcX9zheVVXl10AAgFvjzkkAMAzFDQCGobgBwDAUNwAYhuIGAMNQ3ABgGIobAAxDcQOAYShuADAMxQ0AhqG4AcAwFDcAGIbiBgDDUNwAYBiKGwAM06viPn78uFJTU7V169YuY/v27dOcOXOUnp6uTZs2+T0gAKAz2+JubW1Vbm6ukpKSuh1ft26dXnvtNf35z3/W3r17VVNT4/eQAICv2BZ3aGioioqKFBMT02XszJkzGjp0qEaMGKGQkBClpKSooqIiIEEBADfYFrfT6VRYWFi3Y42NjRo2bJhnOTo6Wo2Njf5LBwDowvaZk7diWVaXdQ6Ho9ttXS6XLy/V7+zytrW1DchjIpd3yOUdcnknULl8Ku7Y2Fi53W7Pcn19ve6+++5ut01ISOjjq5zq4+f5xi6vy+Xy4ZgCh1zeIZd3yOUdX3NVVlZ2u96nywHj4uLU0tKis2fPqr29XXv27FFycrIvuwQA2LA9466qqlJBQYHq6urkdDpVXl6uadOmKS4uTmlpaVq7dq1++ctfSpKefPJJjRs3LuChAeB2ZlvcEydOVHFxcY/jjzzyiEpKSvwaCgDQM+6cBADDUNwAYBiKGwAMQ3EDgGEobgAwDMUNAIahuAHAMBQ3ABiG4gYAw1DcAGAYihsADENxA4BhKG4AMAzFDQCGobgBwDAUNwAYplfPnMzLy9Phw4flcDiUnZ2tSZMmecbeffdd7dq1SyEhIZo4caJWrlwZsLAAgF4U98GDB1VbW6uSkhLV1NRoxYoV2r59uySppaVFmzdv1u7du+V0OrVw4UL985//1IMPPhjo3ABw27KdKqmoqFBqaqokafz48WpublZLS4skafDgwRo8eLBaW1vV3t6uK1euaOjQoYFNDAC3OdszbrfbrcTERM9yVFSUGhsbFR4erjvuuENLlixRamqqwsLCNGvWrB4fFuxyufyXuh/Y5W1raxuQx0Qu75DLO+TyTqBy2Ra3ZVldlh0Oh6QbUyVvvPGG/vrXvyo8PFwLFizQsWPHFB8f32U/CQkJfYx4qo+f5xu7vC6Xy4djChxyeYdc3iGXd3zNVVlZ2e1626mS2NhYud1uz3JDQ4Oio6MlSSdPntTo0aM1bNgwhYaG6uGHH1ZVVVWfQwIA7NkWd3JyssrLyyVJ1dXViomJUXh4uCRp1KhROnnypNra2mRZlqqqqnTPPfcENDAA3O5sp0omT56sxMREZWRkyOFwKCcnR2VlZYqIiFBaWpqeffZZzZ8/X4MGDdJDDz2khx9+uD9yA8Btq1fXcWdlZXVavnkOOyMjQxkZGf5NBQDoEXdOAoBhKG4AMAzFDQCGobgBwDAUNwAYhuIGAMNQ3ABgGIobAAxDcQOAYShuADAMxQ0AhqG4AcAwFDcAGIbiBgDDUNwAYJhe/T/uvLw8HT58WA6HQ9nZ2Zo0aZJn7Pz58/rFL36hL774Qg888IBeeeWVgIUFAPTijPvgwYOqra1VSUmJ1q1bp9zc3E7j+fn5WrhwoUpLSzVo0CCdO3cuYGEBAL0o7oqKCqWmpkqSxo8fr+bmZrW0tEiSOjo6VFlZqWnTpkmScnJyNHLkyADGBQDYFrfb7VZkZKRnOSoqSo2NjZKkpqYmhYeHa+PGjcrMzFRhYaEsywpcWgCA/Rz3/xaxZVlyOByej+vr6/X000/rxRdf1KJFi/TRRx/piSee6LIfl8vln8T9xC5vW1vbgDwmcnmHXN4hl3cClcu2uGNjY+V2uz3LDQ0Nio6OliRFRkZqxIgRGjNmjCQpKSlJJ06c6La4ExIS+hjxVB8/zzd2eV0ulw/HFDjk8g65vEMu7/iaq7Kystv1tlMlycnJKi8vlyRVV1crJiZG4eHhkiSn06nRo0fr9OnTkqSjR49q3LhxfQ4JALBne8Y9efJkJSYmKiMjQw6HQzk5OSorK1NERITS0tKUnZ2tnJwcXb16VRMmTPC8UQkACIxeXcedlZXVaTk+Pt7z8dixY7Vlyxa/hgIA9Iw7JwHAMBQ3ABiG4gYAw1DcAGAYihsADENxA4BhKG4AMAzFDQCGobgBwDAUNwAYhuIGAMNQ3ABgGIobAAxDcQOAYShuADAMxQ0AhulVcefl5Sk9PV0ZGRk6cuRIt9sUFhbqmWee8Ws4AEBXtk/AOXjwoGpra1VSUqKamhqtWLFC27dv77RNTU2NDh06pMGDBwcsKADgBtsz7oqKCqWmpkqSxo8fr+bmZrW0tHTaJj8/X8uXLw9MQgBAJ7Zn3G63W4mJiZ7lqKgoNTY2ep70XlZWpkcffVSjRo265X5cLpePUfuXXd62trYBeUzk8g65vEMu7wQql21xW5bVZdnhcEiSLl26pLKyMr311luqr6+/5X4SEhL6GPFUHz/PN3Z5XS6XD8cUOOTyDrm8Qy7v+JqrsrKy2/W2UyWxsbFyu92e5YaGBkVHR0uS9u/fr6amJs2bN08/+9nPdPToUeXl5fU5JADAnm1xJycnq7y8XJJUXV2tmJgYzzTJzJkz9cEHH+i9997T66+/rsTERGVnZwc2MQDc5mynSiZPnqzExERlZGTI4XAoJydHZWVlioiIUFpaWn9kBADcxLa4JSkrK6vTcnx8fJdt4uLiVFxc7J9UAIAececkABiG4gYAw1DcAGCYXs1x347uefn9XmwVmGvMT+fPCsh+AXw9cMYNAIahuAHAMBQ3ABiG4gYAw1DcAGAYihsADENxA4BhKG4AMAzFDQCGobgBwDAUNwAYplf/qyQvL0+HDx+Ww+FQdna2Jk2a5Bnbv3+/NmzYoJCQEI0bN06/+c1vFBLC7wMACBTbhj148KBqa2tVUlKidevWKTc3t9P4mjVrtHHjRm3btk2XL1/W3r17AxYWANCL4q6oqFBqaqokafz48WpublZLS4tnvKysTMOHD5ckDRs2TBcvXgxQVACA1IvidrvdioyM9CxHRUWpsbHRs/zlg4MbGhq0b98+paSkBCAmAOBLtnPclmV1WXY4HJ3WXbhwQS+88ILWrFnTqeRv5nK5fIh5e/Hla9XW1jYgv9bk8g65vHO75bIt7tjYWLndbs9yQ0ODoqOjPcstLS16/vnntXTpUk2dOrXH/SQkJPQxYmAeVjCQ9f1rdaP0ffn8QCGXd8jlna9rrsrKym7X206VJCcnq7y8XJJUXV2tmJgYz/SIJOXn52vBggVMkQBAP7E94548ebISExOVkZEhh8OhnJwclZWVKSIiQlOnTtXOnTtVW1ur0tJSSdJTTz2l9PT0gAcHgNtVr67jzsrK6rQcHx/v+biqqsq/iQAAt8SdMgBgGIobAAxDcQOAYShuADAMxQ0AhunVVSXoX/e8/L6Pe+jbTUun82f5+LoA+gNn3ABgGIobAAxDcQOAYShuADAMxQ0AhqG4AcAwFDcAGIbiBgDDcAMOPHy/8cdOzzcGcfMP0HuccQOAYXpV3Hl5eUpPT1dGRoaOHDnSaWzfvn2aM2eO0tPTtWnTpoCEBAB8xXaq5ODBg6qtrVVJSYlqamq0YsUKbd++3TO+bt06bd68WbGxsZo7d65mzJih8ePHBzQ04C/fe/uUgvVAaqaH0Fe2xV1RUaHU1FRJ0vjx49Xc3KyWlhaFh4frzJkzGjp0qEaMGCFJSklJUUVFBcUN9IL9ewqB+YXCLwzz2Ra32+1WYmKiZzkqKkqNjY0KDw9XY2Ojhg0b5hmLjo7WmTNnut1PT4+Zt7PjB8P79HkwS19/Pnx1O/58+fq1Dtb3ys7tlMu2uC3L6rLscDi6HZPkGbvZlClT+poPAPA/bN+cjI2Nldvt9iw3NDQoOjq627H6+nrdfffdAYgJAPiSbXEnJyervLxcklRdXa2YmBiFh4dLkuLi4tTS0qKzZ8+qvb1de/bsUXJycmATA8BtzmF1N9/xP9avX69PPvlEDodDOTk5qq6uVkREhNLS0nTo0CGtX79ekjR9+nQ9++yzfgt3/PhxLV68WD/+8Y+VmZnpt/366tVXX1VlZaXa29v105/+VNOnTw92JF25ckUvv/yyLly4oKtXr2rx4sX6zne+E+xYkqS2tjbNmjVLS5Ys0ezZs4MdR5JUVVWlxYsXa+zYsZKk+++/X6tXrw5yqht27dqlN998U06nU0uXLlVKSkqwI2n79u3atWuXZ7mqqkr/+Mc/gpjohsuXL+ull17Sf//7X33xxRdasmSJHn/88WDHUkdHh3JycnTixAkNHjxYa9eu1X333ee/F7AGqMuXL1uZmZnWqlWrrOLi4mDH8aioqLCee+45y7Isq6mpyUpJSQluoP/3/vvvW3/84x8ty7Kss2fPWtOnTw9yoq9s2LDBmj17trVjx45gR/E4cOCAtW7dumDH6KKpqcmaPn269fnnn1v19fXWqlWrgh2piwMHDlhr164NdgzLsiyruLjYWr9+vWVZlvXZZ59ZM2bMCHKiG3bv3m0tXbrUsizLqq2ttRYtWuTX/Q/YW95DQ0NVVFSkoqKiYEfp5JFHHtGkSZMkSUOHDtWVK1d0/fp1DRo0KKi5nnzySc/H58+fV2xsbBDTfOXkyZOqqanRE088EewonVy+fDnYEbpVUVGhpKQkhYeHKzw8XLm5ucGO1MWmTZs8f2UHW2RkpP71r39JkpqbmxUZGRnkRDecPn3a0xNjxozRuXPn/NoTA/aWd6fTqbCwsGDH6GLQoEH6xje+IenGn4/f/va3g17aN8vIyFBWVpays7ODHUWSVFBQoJdffjnYMbpobW1VZWWlnnvuOc2bN0/79+8PdiRJ0tmzZ2VZlpYtW6a5c+eqoqIi2JE6OXLkiEaMGDFgLkKYNWuWzp07p7S0NGVmZuqll14KdiRJN6be/v73v+v69es6deqUzpw5o4sXL/pt/wP2jHug+9vf/qbS0lL96U9/CnaUTrZt2yaXy6Vf/epX2rVrV7eXZ/aXnTt36sEHH9To0aODlqEn8fHxWrJkib773e/q3//+t37yk59o9+7dCg0NDXY01dfX6/XXX9e5c+c0f/587dmzJ6jfx5uVlpbq+9//frBjePzlL3/RyJEjtXnzZh07dkwrV67Ujh07gh1LKSkp+vTTTzVv3jx985vf1L333tvt5dN9RXH3wd69e/WHP/xBb775piIiIoIdR9KNN4uioqI0YsQIJSQk6Pr162pqalJUVFTQMn344Yc6c+aMPvzwQ3322WcKDQ3V8OHD9dhjjwUt05fuu+8+z5tF48aNU3R0tOrr64P+SyYqKkoPPfSQnE6nxowZoyFDhgT9+3izAwcOaNWqVcGO4fHpp59q6tSpkm78Mq6vr1d7e7uczuBX2/Llyz0fp6am+vV7OGCnSgaqzz//XK+++qreeOMN3XXXXcGO4/HJJ594zv7dbrdaW1uDPt/329/+Vjt27NB7772nH/zgB1q8ePGAKG3pxpnjO++8I0lqbGzUhQsXBsT7AlOnTtX+/fvV0dGhpqamAfF9/FJ9fb2GDBkyIP4q+dLYsWN1+PBhSVJdXZ2GDBkyIEr72LFjWrFihSTp448/1gMPPKCQEP/VbfCPsAdVVVUqKChQXV2dnE6nysvL9dprrwW9LD/44ANdvHhRy5Yt86wrKCjQyJEjgxdKN+a2V65cqblz56qtrU1r1qzx6w/K101aWpqysrJUXl6ua9euae3atQOikGJjYzVjxgwtWLBAV65c0apVqwbM9/F//8XFQJCenq7s7GxlZmaqvb1da9euDXYkSTfmuC3LUnp6uiIiIlRQUODX/ffqOm4AwMAxMH6VAwB6jeIGAMNQ3ABgGIobAAxDcQOAYShuADAMxQ0AhqG4AcAw/wcl7uypjxByNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist( [len(v) for k,v in authors.items() if len(v) < 10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b93eb626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2222638"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb2a3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('authors.pickle', 'wb') as outf:\n",
    "    pickle.dump(authors, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af35a624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4688383"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4422f348",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fauthors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-e16bf4b2caa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfauthors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fauthors' is not defined"
     ]
    }
   ],
   "source": [
    "len(fauthors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853247e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fauthors.pickle', 'wb') as outf:\n",
    "    pickle.dump( fauthors, outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3df23",
   "metadata": {},
   "source": [
    "# first counting for all these works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601ae0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file not found. Looking for entry in Harvard Dataverse...\n",
      "No entry found in Harvard dataverse.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Create new folder with name `testing`?:  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading variable testing/_attributes from disk\n",
      "loading variable testing/groups from disk\n"
     ]
    }
   ],
   "source": [
    "# this is where you create the dataset...\n",
    "# perhaps need a better interface here?\n",
    "dta = Dataset('testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3712037",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = counter('testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7837e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation link 10,000,000. Collected 7,883 citations.\n",
      "Citation link 20,000,000. Collected 15,442 citations.\n",
      "Citation link 30,000,000. Collected 23,660 citations.\n",
      "Citation link 40,000,000. Collected 31,266 citations.\n",
      "Citation link 50,000,000. Collected 39,184 citations.\n",
      "Citation link 60,000,000. Collected 55,168 citations.\n",
      "Citation link 70,000,000. Collected 74,516 citations.\n",
      "Citation link 80,000,000. Collected 87,360 citations.\n",
      "Citation link 90,000,000. Collected 91,618 citations.\n",
      "Citation link 100,000,000. Collected 106,147 citations.\n",
      "Citation link 110,000,000. Collected 125,987 citations.\n",
      "Citation link 120,000,000. Collected 146,350 citations.\n",
      "Citation link 130,000,000. Collected 167,253 citations.\n",
      "Citation link 140,000,000. Collected 186,432 citations.\n",
      "Citation link 150,000,000. Collected 206,465 citations.\n",
      "Citation link 160,000,000. Collected 226,198 citations.\n",
      "Citation link 170,000,000. Collected 246,520 citations.\n",
      "Citation link 180,000,000. Collected 266,384 citations.\n",
      "Citation link 190,000,000. Collected 285,897 citations.\n",
      "Citation link 200,000,000. Collected 309,971 citations.\n",
      "Citation link 210,000,000. Collected 334,249 citations.\n",
      "Citation link 220,000,000. Collected 358,856 citations.\n",
      "Citation link 230,000,000. Collected 385,498 citations.\n",
      "Citation link 240,000,000. Collected 412,111 citations.\n",
      "Citation link 250,000,000. Collected 443,919 citations.\n",
      "Citation link 260,000,000. Collected 477,172 citations.\n",
      "Citation link 270,000,000. Collected 510,516 citations.\n",
      "Citation link 280,000,000. Collected 543,331 citations.\n",
      "Citation link 290,000,000. Collected 574,912 citations.\n",
      "Citation link 300,000,000. Collected 606,608 citations.\n",
      "Citation link 310,000,000. Collected 638,900 citations.\n",
      "Citation link 320,000,000. Collected 670,186 citations.\n",
      "Citation link 330,000,000. Collected 703,866 citations.\n",
      "Citation link 340,000,000. Collected 735,918 citations.\n",
      "Citation link 350,000,000. Collected 767,547 citations.\n",
      "Citation link 360,000,000. Collected 799,349 citations.\n",
      "Citation link 370,000,000. Collected 831,938 citations.\n",
      "Citation link 380,000,000. Collected 863,982 citations.\n",
      "Citation link 390,000,000. Collected 896,713 citations.\n",
      "Citation link 400,000,000. Collected 929,047 citations.\n",
      "Citation link 410,000,000. Collected 961,978 citations.\n",
      "Citation link 420,000,000. Collected 995,093 citations.\n",
      "Citation link 430,000,000. Collected 1,028,376 citations.\n",
      "Citation link 440,000,000. Collected 1,060,417 citations.\n",
      "Citation link 450,000,000. Collected 1,092,850 citations.\n",
      "Citation link 460,000,000. Collected 1,125,792 citations.\n",
      "Citation link 470,000,000. Collected 1,158,624 citations.\n",
      "Citation link 480,000,000. Collected 1,192,110 citations.\n",
      "Citation link 490,000,000. Collected 1,225,012 citations.\n",
      "Citation link 500,000,000. Collected 1,257,936 citations.\n",
      "Citation link 510,000,000. Collected 1,291,053 citations.\n",
      "Citation link 520,000,000. Collected 1,322,546 citations.\n",
      "Citation link 530,000,000. Collected 1,355,339 citations.\n",
      "Citation link 540,000,000. Collected 1,387,707 citations.\n",
      "Citation link 550,000,000. Collected 1,421,245 citations.\n",
      "Citation link 560,000,000. Collected 1,454,181 citations.\n",
      "Citation link 570,000,000. Collected 1,486,945 citations.\n",
      "Citation link 580,000,000. Collected 1,518,550 citations.\n",
      "Citation link 590,000,000. Collected 1,551,628 citations.\n",
      "Citation link 600,000,000. Collected 1,583,173 citations.\n",
      "Citation link 610,000,000. Collected 1,615,602 citations.\n",
      "Citation link 620,000,000. Collected 1,647,928 citations.\n",
      "Citation link 630,000,000. Collected 1,681,277 citations.\n",
      "Citation link 640,000,000. Collected 1,714,671 citations.\n",
      "Citation link 650,000,000. Collected 1,746,796 citations.\n",
      "Citation link 660,000,000. Collected 1,779,895 citations.\n",
      "Citation link 670,000,000. Collected 1,811,534 citations.\n",
      "Citation link 680,000,000. Collected 1,844,223 citations.\n",
      "Citation link 690,000,000. Collected 1,878,246 citations.\n"
     ]
    }
   ],
   "source": [
    "with Path(home, 'datasets/s4/MAG/PaperReferences.txt').open() as inf:\n",
    "    for i,l in enumerate(inf):\n",
    "        if (i+1)%1e7 == 0:\n",
    "            print(f\"Citation link {i+1:,}. Collected {sum(c.ind['fy'].values()):,} citations.\")\n",
    "        \n",
    "        l = l[:-1] # strip the trailing \\n from the line\n",
    "        l = l.split('\\t') # tab delimited\n",
    "        l = list(map(int,l)) # map to integers. saving on memory this way hopefully\n",
    "        #print(l)\n",
    "        \n",
    "        citing, cited = l[0], l[1]\n",
    "        if citing not in socpapers_filt or cited not in socpapers_filt: # interesting question, should I consider only citations to other soc papers?\n",
    "            continue\n",
    "            \n",
    "        fy = infos[ citing ][1]\n",
    "        ty = infos[ cited ][1]\n",
    "        fj = infos[ citing ][2]\n",
    "        tj = infos[ citing ][2]\n",
    "\n",
    "        #c.cnt(doc.journal, 'fj', citing)\n",
    "        c.cnt(fy, 'fy', citing)\n",
    "        c.cnt(ty, 'ty', citing)\n",
    "        c.cnt((cited, fy), 'c.fy', citing)\n",
    "        c.cnt((cited, fj), 'c.fj', citing)\n",
    "\n",
    "        c.cnt((fj, fy), 'fj.fy', citing)\n",
    "\n",
    "        c.cnt(cited, 'c', citing)\n",
    "\n",
    "        c.cnt((fy, ty), 'fy.ty', citing)\n",
    "        c.cnt((fj, ty), 'fj.ty', citing)\n",
    "\n",
    "        for a in authors[cited]:\n",
    "            c.cnt(a, 'ta', citing)\n",
    "            c.cnt((fy, a), 'fy.ta', citing)\n",
    "            c.cnt((fj, a), 'fj.ta', citing)\n",
    "\n",
    "        #c.cnt((cited, doc.journal, fy), 'c.fj.fy', citing)\n",
    "\n",
    "        # first author!\n",
    "        if False:\n",
    "            ffa = fauthors[citing]\n",
    "            c.cnt(ffa, 'ffa', citing)\n",
    "            c.cnt((ffa, fy), 'ffa.fy', citing)\n",
    "            c.cnt((ffa, doc.journal), 'ffa.fj', citing)\n",
    "            c.cnt((cited, ffa), 'c.ffa', citing)\n",
    "            # c.cnt((ffa,r['SO'], int(r['PY'])), 'ffa.fj.fy', citing)\n",
    "\n",
    "        for a in authors[citing]:\n",
    "            c.cnt(a, 'fa', citing)\n",
    "            c.cnt((a, fy), 'fa.fy', citing)\n",
    "            # c.cnt((a, doc.journal), 'fa.fj', citing)\n",
    "            # c.cnt((a,r['SO'], int(r['PY'])), 'fa.fj.fy', citing)\n",
    "\n",
    "            c.cnt((cited, a), 'c.fa', citing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af601c",
   "metadata": {},
   "source": [
    "# now do some counting for ages..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbirthdays = defaultdict(lambda: 2050)\n",
    "for (c, y), count in c.doc['c.fy'].items():\n",
    "    if count == 0:\n",
    "        continue\n",
    "    cbirthdays[c] = min(cbirthdays[c], y)\n",
    "\n",
    "ffabirthdays = defaultdict(lambda: 2050)\n",
    "for (c, y), count in c.doc['ffa.fy'].items():\n",
    "    if count == 0:\n",
    "        continue\n",
    "    ffabirthdays[c] = min(ffabirthdays[c], y)\n",
    "\n",
    "tabirthdays = defaultdict(lambda: 2050)\n",
    "for (y, c), count in c.doc['fy.ta'].items():\n",
    "    if count == 0:\n",
    "        continue\n",
    "    tabirthdays[c] = min(tabirthdays[c], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/s4/MAG/PaperReferences.txt') as inf:\n",
    "    \n",
    "    for i,l in enumerate(inf):\n",
    "        if (i+1)%1e7 == 0:\n",
    "            print(f'Citation link {i+1:,}. Collected {len(clinks):,}.')\n",
    "        \n",
    "        l = l[:-1] # strip the trailing \\n from the line\n",
    "        l = l.split('\\t') # tab delimited\n",
    "        l = list(map(int,l)) # map to integers. saving on memory this way hopefully\n",
    "        \n",
    "        citing, cited = l[0], l[1]\n",
    "        if citing not in socpapers_filt or cited not in socpapers_filt: # interesting question, should I consider only citations to other soc papers?\n",
    "            continue\n",
    "        \n",
    "        #ffa = fauthors[citing]\n",
    "        #fta = fauthors[cited]\n",
    "        \n",
    "        fas = authors[citing]\n",
    "        tas = authors[cited]\n",
    "\n",
    "        # skips the hitherto uncounted\n",
    "        #if cited not in c.doc['c'] or c.doc['c'][cited] == 0:\n",
    "        #    continue\n",
    "        #if ffa not in c.doc['ffa'] or c.doc['ffa'][ffa] == 0:\n",
    "        #    continue\n",
    "        #if fta not in c.doc['ta'] or c.doc['ta'][fta] == 0:\n",
    "        #    continue\n",
    "\n",
    "        cage1 = fy - cbirthdays[cited]\n",
    "        \n",
    "        #ffaage1 = fy - ffabirthdays[ffa]\n",
    "        #ftaage1 = fy - tabirthdays[fta]\n",
    "\n",
    "        #if not all(x >= 0 for x in [cage1, ffaage1, taage1]):\n",
    "        #    print(cage1, ffaage1, taage1)\n",
    "        #    raise\n",
    "\n",
    "        #c.cnt((cage1, doc.journal), 'cAge.fj', citing)\n",
    "\n",
    "        c.cnt((cage1, doc.citing_authors[0]), 'cAge.ffa', citing)\n",
    "        for author in fas:\n",
    "            faage1 = fy - ffabirthdays[author]\n",
    "            c.cnt((cage1, author), 'cAge.fa', citing)\n",
    "            c.cnt(faage1, 'faAge', citing)\n",
    "\n",
    "            c.cnt((faage1, ref.author), 'faAge.ta', citing)\n",
    "            c.cnt((faage1, fy, ref.author), 'faAge.fy.ta', citing)\n",
    "            c.cnt((cage1, faage1), 'cAge.faAge', citing)\n",
    "\n",
    "            c.cnt((faage1, fy), 'faAge.fy', citing)\n",
    "            \n",
    "            for ta in tas:\n",
    "                taage1 = fy - ffabirthdays[ta]\n",
    "                c.cnt((faage1, taage1), 'faAge.taAge', citing)\n",
    "\n",
    "        if False:\n",
    "            c.cnt(ffaage1, 'ffaAge', citing)\n",
    "\n",
    "            c.cnt((ffaage1, ref.author), 'ffaAge.ta', citing)\n",
    "            c.cnt((ffaage1, fy, ref.author), 'ffaAge.fy.ta', citing)\n",
    "            c.cnt((ffaage1, taage1), 'ffaAge.taAge', citing)\n",
    "            c.cnt((cage1, ffaage1), 'cAge.ffaAge', citing)\n",
    "            c.cnt((ffaage1, fy), 'ffaAge.fy', citing)\n",
    "\n",
    "        c.cnt((cage1, fy), 'cAge.fy', citing)\n",
    "        \n",
    "        for author in tas:\n",
    "            taage1 = fy - ffabirthdays[author]\n",
    "            c.cnt((fy, taage1), 'fy.taAge', citing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b946ab4",
   "metadata": {},
   "source": [
    "# and finally, save the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17982e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowknow.dataverse import upload\n",
    "upload(\n",
    "    api_key = env.GLOBS['dataverse_api_key'],\n",
    "    dataset_name = 'sociology-mag-internal-1',\n",
    "    dataset_description = \"\"\"All the sociology -> sociology journal citations from MAG, from all journals. Includes citing and cited age distributions.\"\"\",\n",
    "    dataverse_name = 'kk-citation-counts',\n",
    "    dataverse_server = 'https://dataverse.harvard.edu'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
